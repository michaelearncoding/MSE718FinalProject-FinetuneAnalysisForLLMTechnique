#!/bin/bash

# å¿«é€Ÿæµ‹è¯•è„šæœ¬ - éªŒè¯å®žéªŒæµç¨‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
# ä½¿ç”¨æžå°‘çš„æ•°æ®å’Œè®­ç»ƒæ­¥éª¤ï¼Œç›®çš„ä»…ä¸ºéªŒè¯æµç¨‹æ— bug

echo "=================================================="
echo "ðŸ§ª å¼€å§‹å®žéªŒæµç¨‹å¿«é€Ÿæµ‹è¯•"
echo "=================================================="

# ç¡®ä¿ç›®å½•ç»“æž„æ­£ç¡®
mkdir -p data
mkdir -p models
mkdir -p results/raw_data
mkdir -p results/figures
mkdir -p results/model_comparison

# æ­¥éª¤1: æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶å’Œå·¥å…·
echo "1ï¸âƒ£ æ£€æŸ¥å¿…è¦çš„è„šæœ¬å’Œå·¥å…·..."

MISSING_FILES=0
for FILE in scripts/train_instruction.py scripts/evaluate_models.sh scripts/analyze_results.py scripts/run_mac_friendly.sh; do
    if [ ! -f "$FILE" ]; then
        echo "âŒ ç¼ºå°‘æ–‡ä»¶: $FILE"
        MISSING_FILES=1
    fi
done

if [ $MISSING_FILES -eq 1 ]; then
    echo "è¯·ç¡®ä¿æ‰€æœ‰å¿…è¦çš„è„šæœ¬æ–‡ä»¶å­˜åœ¨!"
    exit 1
fi

echo "âœ… æ‰€æœ‰å¿…è¦è„šæœ¬æ–‡ä»¶å­˜åœ¨"

# æ­¥éª¤2: æ£€æŸ¥Pythonä¾èµ–
echo "2ï¸âƒ£ æ£€æŸ¥Pythonä¾èµ–..."
python -c "import torch; import transformers; import peft; import datasets; import matplotlib.pyplot as plt; print('âœ… æ‰€æœ‰Pythonä¾èµ–å·²å®‰è£…')" || { echo "âŒ ç¼ºå°‘å¿…è¦çš„Pythonä¾èµ–"; exit 1; }

# æ­¥éª¤3: åˆ›å»ºæµ‹è¯•æ•°æ®é›†(åªå«3ä¸ªæ ·æœ¬çš„æžå°æ•°æ®é›†)
echo "3ï¸âƒ£ åˆ›å»ºæµ‹è¯•æ•°æ®é›†..."
cat > data/tiny_test.jsonl << EOF
{"instruction": "å†™ä¸€ä¸ªç®€çŸ­çš„é—®å€™è¯­", "input": "", "output": "ä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚å¸Œæœ›ä½ ä»Šå¤©è¿‡å¾—æ„‰å¿«ï¼"}
{"instruction": "è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ", "input": "", "output": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿ç”¨æ•°æ®æ¥è®­ç»ƒç®—æ³•ï¼Œä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜Žç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚"}
{"instruction": "ç”¨ä¸€å¥è¯æè¿°åœ°çƒ", "input": "", "output": "åœ°çƒæ˜¯å¤ªé˜³ç³»ä¸­ç¬¬ä¸‰é¢—è¡Œæ˜Ÿï¼Œæ˜¯å·²çŸ¥å”¯ä¸€å­•è‚²äº†ç”Ÿå‘½çš„å¤©ä½“ï¼Œæ‹¥æœ‰æ¶²æ€æ°´å’Œç»´æŒç”Ÿå‘½çš„å¤§æ°”å±‚ã€‚"}
EOF

echo "âœ… æµ‹è¯•æ•°æ®é›†å·²åˆ›å»º: data/tiny_test.jsonl (3ä¸ªæ ·æœ¬)"

# æ­¥éª¤4: æµ‹è¯•è®­ç»ƒè„šæœ¬(ä½¿ç”¨æœ€å°çš„tinyæ¨¡åž‹å’Œqloraæ–¹æ³•)
echo "4ï¸âƒ£ æµ‹è¯•è®­ç»ƒè„šæœ¬..."
# ä¿®æ”¹è®­ç»ƒå‚æ•°ä»¥åŠ é€Ÿæµ‹è¯•(æœ€å°æ‰¹æ¬¡ï¼Œæœ€å°‘æ­¥éª¤)
TEST_CMD="python scripts/train_instruction.py --method qlora --model_size tiny --epochs 1 --batch_size 1 --gradient_accumulation_steps 1 --use_mps"
echo "æ‰§è¡Œ: $TEST_CMD"

# ä¸´æ—¶ä¿®æ”¹è®­ç»ƒè„šæœ¬ä»¥ä½¿ç”¨æµ‹è¯•æ•°æ®
cp scripts/train_instruction.py scripts/train_instruction.py.backup
sed -i '' 's|TRAIN_FILE = "data/alpaca_train.jsonl"|TRAIN_FILE = "data/tiny_test.jsonl"|g' scripts/train_instruction.py
sed -i '' 's|args.epochs, batch_size=args.batch_size|1, batch_size=1|g' scripts/train_instruction.py

# è¿è¡Œæµ‹è¯•è®­ç»ƒ(é™åˆ¶5åˆ†é’Ÿ)
timeout 300 $TEST_CMD
TRAIN_RESULT=$?

# æ¢å¤åŽŸå§‹è®­ç»ƒè„šæœ¬
mv scripts/train_instruction.py.backup scripts/train_instruction.py

if [ $TRAIN_RESULT -eq 124 ]; then
    echo "âš ï¸ è®­ç»ƒæµ‹è¯•è¶…æ—¶ï¼Œä½†è¿™ä¸ä¸€å®šæ˜¯é”™è¯¯ - è®­ç»ƒé€šå¸¸å¾ˆè€—æ—¶"
    echo "âœ… è„šæœ¬å¯åŠ¨æ­£å¸¸"
elif [ $TRAIN_RESULT -ne 0 ]; then
    echo "âŒ è®­ç»ƒè„šæœ¬æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯"
    exit 1
else
    echo "âœ… è®­ç»ƒè„šæœ¬æµ‹è¯•æˆåŠŸ"
fi

# æ­¥éª¤5: åˆ›å»ºæ¨¡æ‹Ÿè¯„ä¼°ç»“æžœ(è·³è¿‡å®žé™…è¯„ä¼°ä»¥èŠ‚çœæ—¶é—´)
echo "5ï¸âƒ£ åˆ›å»ºæ¨¡æ‹Ÿè¯„ä¼°ç»“æžœ..."
mkdir -p results/model_comparison
cat > results/model_comparison/tinyllama_1.1b_base.json << EOF
{
    "results": {
        "hellaswag": {
            "acc,none": 0.42
        },
        "gsm8k": {
            "acc,none": 0.11
        },
        "mmlu_high_school_computer_science": {
            "acc,none": 0.36
        }
    }
}
EOF

cat > results/model_comparison/tinyllama_1.1b_qlora.json << EOF
{
    "results": {
        "hellaswag": {
            "acc,none": 0.47
        },
        "gsm8k": {
            "acc,none": 0.15
        },
        "mmlu_high_school_computer_science": {
            "acc,none": 0.41
        }
    }
}
EOF

echo "âœ… æ¨¡æ‹Ÿè¯„ä¼°ç»“æžœå·²åˆ›å»º"

# æ­¥éª¤6: æµ‹è¯•åˆ†æžè„šæœ¬
echo "6ï¸âƒ£ æµ‹è¯•åˆ†æžè„šæœ¬..."
python scripts/analyze_results.py
if [ $? -ne 0 ]; then
    echo "âŒ åˆ†æžè„šæœ¬æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯"
    exit 1
else
    echo "âœ… åˆ†æžè„šæœ¬æµ‹è¯•æˆåŠŸ"
fi

echo "=================================================="
echo "ðŸŽ‰ å¿«é€Ÿæµ‹è¯•å®Œæˆ!"
echo "=================================================="
echo "æ‰€æœ‰å…³é”®ç»„ä»¶æµ‹è¯•é€šè¿‡!"
echo ""
echo "å»ºè®®ä¸‹ä¸€æ­¥:"
echo "1. ç¡®ä¿æ•°æ®é›†å‡†å¤‡å¥½ (data/alpaca_train.jsonl)"
echo "2. ç¡®ä¿è¯„ä¼°æ¡†æž¶å·²å…‹éš† (lm-evaluation-harness)"
echo "3. è¿è¡Œå®Œæ•´å®žéªŒ: ./scripts/run_mac_friendly.sh tiny 'qlora'"
echo "==================================================" 